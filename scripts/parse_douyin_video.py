#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è§£ææŠ–éŸ³åˆ†äº«é“¾æ¥ï¼Œä¸‹è½½è§†é¢‘ï¼Œå¹¶è½¬æˆæ–‡å­—
å‚è€ƒ: ParseDouyinShareUrl.php
"""

import argparse
import json
import os
import re
import random
import string
import sys
from pathlib import Path
from urllib.parse import urlparse, parse_qs
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# User Agent
USER_AGENT = 'Mozilla/5.0 (iPhone; CPU iPhone OS 26_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/26.0 Mobile/15E148 Safari/604.1'


def create_session():
    """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„requests session"""
    session = requests.Session()
    retry_strategy = Retry(
        total=3,
        backoff_factor=1,
        status_forcelist=[429, 500, 502, 503, 504],
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    return session


def rand_seq(n):
    """ç”Ÿæˆéšæœºå­—ç¬¦ä¸²"""
    letters = string.ascii_letters + string.digits
    return ''.join(random.choice(letters) for _ in range(n))


def generate_fixed_length_numeric_id(length):
    """ç”Ÿæˆå›ºå®šä½æ•°çš„éšæœºæ•°å­—ï¼ˆå‰å¯¼é›¶ï¼‰"""
    max_num = 10 ** length
    random_num = random.randint(0, max_num - 1)
    return str(random_num).zfill(length)


def get_no_webp_url(url_list):
    """ä¼˜å…ˆè·å–é .webp æ ¼å¼çš„å›¾ç‰‡ url"""
    for url in url_list:
        if '.webp' not in url:
            return url
    return url_list[0] if url_list else ''


def get_canonical_from_html(html_content):
    """ä» HTML å­—ç¬¦ä¸²è·å– canonical URL"""
    match = re.search(r'<link[^>]*rel=["\']canonical["\'][^>]*href=["\']([^"\']+)["\']', html_content, re.IGNORECASE)
    if match:
        return match.group(1)
    return None


def parse_video_id_from_path(url_path):
    """ä»è·¯å¾„ä¸­æå–è§†é¢‘ID"""
    if not url_path:
        return None
    
    # å¦‚æœæ˜¯å®Œæ•´URLï¼Œå…ˆè§£æ
    if url_path.startswith('http://') or url_path.startswith('https://'):
        parsed = urlparse(url_path)
    else:
        parsed = urlparse('http://example.com' + url_path)
    
    # åˆ¤æ–­ç½‘é¡µç²¾é€‰é¡µé¢çš„è§†é¢‘
    # https://www.douyin.com/jingxuan?modal_id=xxxx
    if parsed.query:
        query_params = parse_qs(parsed.query)
        if 'modal_id' in query_params and query_params['modal_id']:
            return query_params['modal_id'][0]
    
    # åˆ¤æ–­å…¶ä»–é¡µé¢çš„è§†é¢‘
    # https://www.iesdouyin.com/share/video/xxxx
    path = parsed.path.strip('/')
    if not path:
        return None
    
    path_parts = path.split('/')
    if path_parts:
        return path_parts[-1]
    
    return None


def convert_ssr_data_to_standard_format(video_data):
    """å°† SSR æ•°æ®æ ¼å¼è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼"""
    avatar_url_list = []
    if 'author' in video_data and 'avatar_thumb' in video_data['author']:
        if isinstance(video_data['author']['avatar_thumb'], dict) and 'url_list' in video_data['author']['avatar_thumb']:
            avatar_url_list = video_data['author']['avatar_thumb']['url_list']
        elif isinstance(video_data['author']['avatar_thumb'], str):
            avatar_url_list = [video_data['author']['avatar_thumb']]
    
    result = {
        'desc': video_data.get('desc', ''),
        'author': {
            'sec_uid': video_data.get('author', {}).get('sec_uid', ''),
            'nickname': video_data.get('author', {}).get('nickname', ''),
            'avatar_thumb': {
                'url_list': avatar_url_list
            },
        },
    }
    
    # å¤„ç†è§†é¢‘æ•°æ®
    if 'video' in video_data:
        video = video_data['video']
        play_url_list = []
        if 'playAddr' in video and 'url_list' in video['playAddr']:
            play_url_list = video['playAddr']['url_list']
        elif 'play_addr' in video and 'url_list' in video['play_addr']:
            play_url_list = video['play_addr']['url_list']
        
        cover_url_list = []
        if 'cover' in video and 'url_list' in video['cover']:
            cover_url_list = video['cover']['url_list']
        
        result['video'] = {
            'play_addr': {
                'url_list': play_url_list
            },
            'cover': {
                'url_list': cover_url_list
            },
        }
    
    # å¤„ç†å›¾ç‰‡æ•°æ®
    if 'images' in video_data and isinstance(video_data['images'], list):
        result['images'] = video_data['images']
    
    return result


def extract_video_data_from_html(html, video_id):
    """ä»HTMLä¸­æå–è§†é¢‘æ•°æ®ï¼ˆå¤šç§æ–¹æ³•ï¼‰"""
    # æ–¹æ³•1: å°è¯•ä» window._ROUTER_DATA æå–ï¼ˆä¸»è¦æ–¹æ³•ï¼‰
    match = re.search(r'window\._ROUTER_DATA\s*=\s*(.*?)</script>', html, re.DOTALL)
    if match:
        json_str = match.group(1).strip()
        try:
            json_data = json.loads(json_str)
            if json_data and 'loaderData' in json_data:
                # HTMLä¸­çš„è·¯å¾„æ˜¯å›ºå®šçš„ "video_(id)/page"
                page_key = 'video_(id)/page'
                if page_key not in json_data['loaderData']:
                    page_key = f'video_{video_id}/page'
                
                if page_key in json_data['loaderData']:
                    page_data = json_data['loaderData'][page_key]
                    if 'videoInfoRes' in page_data and 'item_list' in page_data['videoInfoRes']:
                        if page_data['videoInfoRes']['item_list']:
                            return page_data['videoInfoRes']['item_list'][0]
                        elif 'filter_list' in page_data['videoInfoRes']:
                            filter_list = page_data['videoInfoRes']['filter_list']
                            for filter_item in filter_list:
                                if filter_item.get('aweme_id') == video_id:
                                    raise Exception(
                                        f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {filter_item.get('filter_reason', 'æœªçŸ¥åŸå› ')} - {filter_item.get('detail_msg', '')}"
                                    )
        except json.JSONDecodeError:
            pass
    
    # æ–¹æ³•2: å°è¯•ä» window._SSR_HYDRATED_DATA æå–
    match = re.search(r'window\._SSR_HYDRATED_DATA\s*=\s*({.+?});', html, re.DOTALL)
    if match:
        json_str = match.group(1)
        if '&' in json_str:
            import html as html_module
            json_str = html_module.unescape(json_str)
        try:
            json_data = json.loads(json_str)
            if json_data and 'defaultScope' in json_data and 'videoData' in json_data['defaultScope']:
                return convert_ssr_data_to_standard_format(json_data['defaultScope']['videoData'])
        except (json.JSONDecodeError, KeyError):
            pass
    
    # æ–¹æ³•3: å°è¯•ä» RENDER_DATA script æ ‡ç­¾æå–
    match = re.search(r'<script[^>]*id=["\']RENDER_DATA["\'][^>]*>(.+?)</script>', html, re.DOTALL)
    if match:
        json_str = match.group(1).strip()
        if '%' in json_str:
            from urllib.parse import unquote
            json_str = unquote(json_str)
        try:
            json_data = json.loads(json_str)
            if json_data and 'defaultScope' in json_data:
                if 'videoData' in json_data['defaultScope']:
                    return convert_ssr_data_to_standard_format(json_data['defaultScope']['videoData'])
                elif 'aweme' in json_data['defaultScope']:
                    return convert_ssr_data_to_standard_format(json_data['defaultScope']['aweme'])
        except (json.JSONDecodeError, KeyError):
            pass
    
    # æ–¹æ³•4: å°è¯•ä» window.RENDER_DATA æå–
    match = re.search(r'window\.RENDER_DATA\s*=\s*({.+?});', html, re.DOTALL)
    if match:
        json_str = match.group(1)
        if '&' in json_str:
            import html as html_module
            json_str = html_module.unescape(json_str)
        if '%' in json_str:
            from urllib.parse import unquote
            json_str = unquote(json_str)
        try:
            json_data = json.loads(json_str)
            if json_data and 'defaultScope' in json_data and 'videoData' in json_data['defaultScope']:
                return convert_ssr_data_to_standard_format(json_data['defaultScope']['videoData'])
        except (json.JSONDecodeError, KeyError):
            pass
    
    # æ–¹æ³•5: å°è¯•ç›´æ¥åŒ¹é… videoData æˆ– aweme_detail
    patterns = [
        r'"videoData":\s*({.+?}),',
        r'"aweme_detail":\s*({.+?}),',
        r'"itemList":\s*\[({.+?})\]',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, html, re.DOTALL)
        if match:
            json_str = match.group(1)
            if '&' in json_str:
                import html as html_module
                json_str = html_module.unescape(json_str)
            if '%' in json_str:
                from urllib.parse import unquote
                json_str = unquote(json_str)
            try:
                json_data = json.loads(json_str)
                if json_data:
                    return convert_ssr_data_to_standard_format(json_data)
            except (json.JSONDecodeError, KeyError):
                pass
    
    return None


def get_redirect_url(session, video_url):
    """è·å–é‡å®šå‘åçš„è§†é¢‘åœ°å€"""
    if not video_url:
        return video_url
    
    try:
        response = session.get(video_url, allow_redirects=False, headers={'User-Agent': USER_AGENT}, timeout=10)
        if 300 <= response.status_code < 400:
            location = response.headers.get('Location')
            if location:
                return location
    except Exception:
        pass
    
    return video_url


def parse_video_id(video_id, session):
    """æ ¹æ®è§†é¢‘IDè§£æè§†é¢‘ä¿¡æ¯"""
    # æ­¥éª¤1ï¼šè¯·æ±‚æŠ–éŸ³é¡µé¢
    req_url = f"https://www.iesdouyin.com/share/video/{video_id}"
    
    response = session.get(req_url, headers={'User-Agent': USER_AGENT}, timeout=30)
    if not response.ok:
        raise Exception(f'è¯·æ±‚å¤±è´¥: {response.status_code}')
    
    html = response.text
    
    # æ­¥éª¤2ï¼šåˆ¤æ–­æ˜¯å¦æ˜¯å›¾é›†ï¼ˆNoteï¼‰
    is_note = False
    canonical = get_canonical_from_html(html)
    if canonical and '/note/' in canonical:
        is_note = True
    
    data = None
    
    # è·å–å›¾é›†
    if is_note:
        web_id = '75' + generate_fixed_length_numeric_id(15)
        a_bogus = rand_seq(64)
        
        api_url = (
            f'https://www.iesdouyin.com/web/api/v2/aweme/slidesinfo/?reflow_source=reflow_page'
            f'&web_id={web_id}&device_id={web_id}&aweme_ids=%5B{video_id}%5D'
            f'&request_source=200&a_bogus={a_bogus}'
        )
        
        api_response = session.get(api_url, headers={'User-Agent': USER_AGENT}, timeout=30)
        if api_response.ok:
            json_data = api_response.json()
            if json_data.get('aweme_details') and len(json_data['aweme_details']) > 0:
                data = json_data['aweme_details'][0]
            else:
                is_note = False
        else:
            is_note = False
    
    # è·å–è§†é¢‘
    if not is_note:
        data = extract_video_data_from_html(html, video_id)
        if not data:
            raise Exception('ä»HTMLä¸­è§£æè§†é¢‘JSONä¿¡æ¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æŠ–éŸ³é¡µé¢ç»“æ„æ˜¯å¦å·²æ›´æ–°')
    
    if not data:
        raise Exception('æ— æ³•è·å–è§†é¢‘æ•°æ®')
    
    # è·å–å›¾é›†å›¾ç‰‡åœ°å€
    images = []
    if 'images' in data and isinstance(data['images'], list):
        for image_item in data['images']:
            url_list = image_item.get('url_list', [])
            image_url = get_no_webp_url(url_list)
            if image_url:
                images.append({
                    'url': image_url,
                    'live_photo_url': image_item.get('video', {}).get('play_addr', {}).get('url_list', [None])[0],
                })
    
    # æ­¥éª¤4ï¼šæå–è§†é¢‘æ’­æ”¾åœ°å€
    video_url = ''
    if not is_note and 'video' in data and 'play_addr' in data['video']:
        url_list = data['video']['play_addr'].get('url_list', [])
        if url_list:
            # å°† playwm æ›¿æ¢ä¸º playï¼Œè·å–æ— æ°´å°è§†é¢‘
            video_url = url_list[0].replace('playwm', 'play')
    
    # å¦‚æœå›¾é›†åœ°å€ä¸ä¸ºç©ºæ—¶ï¼Œå› ä¸ºæ²¡æœ‰è§†é¢‘ï¼Œä¸Šé¢æŠ–éŸ³è¿”å›çš„è§†é¢‘åœ°å€æ— æ³•è®¿é—®ï¼Œç½®ç©ºå¤„ç†
    if images:
        video_url = ''
    
    # è·å–å°é¢
    cover_url = ''
    if 'video' in data and 'cover' in data['video']:
        url_list = data['video']['cover'].get('url_list', [])
        if url_list:
            cover_url = get_no_webp_url(url_list)
    
    result = {
        'title': data.get('desc', ''),
        'video_url': video_url,
        'cover_url': cover_url,
        'images': images,
        'author': {
            'uid': data.get('author', {}).get('sec_uid', ''),
            'name': data.get('author', {}).get('nickname', ''),
            'avatar': data.get('author', {}).get('avatar_thumb', {}).get('url_list', [None])[0],
        },
    }
    
    # æ­¥éª¤5ï¼šè·å–302é‡å®šå‘ä¹‹åçš„çœŸå®è§†é¢‘åœ°å€
    if result['video_url']:
        result['video_url'] = get_redirect_url(session, result['video_url'])
    
    if not result['video_url'] and not result['images']:
        raise Exception('æ²¡æœ‰ä½œå“')
    
    return result


def parse_app_share_url(share_url, session):
    """è§£æAppåˆ†äº«é“¾æ¥"""
    # ç¦ç”¨é‡å®šå‘ï¼Œè·å–é‡å®šå‘å‰çš„å‚æ•°
    response = session.get(share_url, allow_redirects=False, headers={'User-Agent': USER_AGENT}, timeout=30)
    
    if 300 <= response.status_code < 400:
        location = response.headers.get('Location')
        if location:
            parsed_location = urlparse(location)
            if parsed_location.path:
                video_id = parse_video_id_from_path(parsed_location.path)
                if video_id:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯è¥¿ç“œè§†é¢‘
                    if parsed_location.hostname and 'ixigua.com' in parsed_location.hostname:
                        raise Exception('è¥¿ç“œè§†é¢‘æš‚ä¸æ”¯æŒ')
                    return parse_video_id(video_id, session)
    
    raise Exception('æ— æ³•ä»åˆ†äº«é“¾æ¥ä¸­æå–è§†é¢‘ID')


def parse_pc_share_url(share_url, session):
    """è§£æPCç«¯åˆ†äº«é“¾æ¥"""
    video_id = parse_video_id_from_path(share_url)
    if not video_id:
        raise Exception('æ— æ³•ä»URLä¸­æå–è§†é¢‘ID')
    return parse_video_id(video_id, session)


def parse_share_url(share_url, session):
    """è§£æåˆ†äº«é“¾æ¥"""
    parsed_url = urlparse(share_url)
    if not parsed_url.hostname:
        raise Exception('æ— æ•ˆçš„URL')
    
    host = parsed_url.hostname
    
    if host in ['www.iesdouyin.com', 'www.douyin.com']:
        return parse_pc_share_url(share_url, session)
    elif host == 'v.douyin.com':
        return parse_app_share_url(share_url, session)
    else:
        raise Exception(f"ä¸æ”¯æŒçš„åŸŸå: {host}")


def download_video(video_url, output_path, session):
    """ä¸‹è½½è§†é¢‘"""
    response = session.get(video_url, headers={'User-Agent': USER_AGENT}, stream=True, timeout=60)
    response.raise_for_status()
    
    total_size = int(response.headers.get('content-length', 0))
    
    with open(output_path, 'wb') as f:
        downloaded = 0
        for chunk in response.iter_content(chunk_size=8192):
            if chunk:
                f.write(chunk)
                downloaded += len(chunk)
                if total_size > 0:
                    percent = (downloaded / total_size) * 100
                    print(f"\rä¸‹è½½è¿›åº¦: {percent:.1f}%", end='', flush=True)
    
    print()  # æ¢è¡Œ
    return output_path


def main():
    parser = argparse.ArgumentParser(description='è§£ææŠ–éŸ³åˆ†äº«é“¾æ¥ï¼Œä¸‹è½½è§†é¢‘ï¼Œå¹¶è½¬æˆæ–‡å­—')
    parser.add_argument('url', type=str, help='æŠ–éŸ³åˆ†äº«é“¾æ¥')
    parser.add_argument('--output-dir', type=str, default=None, help='è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰å·¥ä½œç›®å½•ä¸‹çš„ downloads/')
    parser.add_argument('--transcribe', action='store_true', help='æ˜¯å¦è½¬æ–‡å­—ï¼ˆéœ€è¦å®‰è£…FunASRï¼‰')
    parser.add_argument('--model', type=str, default='paraformer-zh', help='ASRæ¨¡å‹ï¼Œé»˜è®¤ä¸º paraformer-zh')
    parser.add_argument('--vad-model', type=str, default='fsmn-vad', help='VADæ¨¡å‹ï¼Œé»˜è®¤ä¸º fsmn-vad')
    parser.add_argument('--punc-model', type=str, default='ct-punc', help='æ ‡ç‚¹æ¢å¤æ¨¡å‹ï¼Œé»˜è®¤ä¸º ct-punc')
    
    args = parser.parse_args()
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºç›®å½•ï¼Œæ™ºèƒ½åˆ¤æ–­ä¸‹è½½ä½ç½®
    if args.output_dir is None:
        current_cwd = Path.cwd().resolve()
        script_dir = Path(__file__).parent.resolve()
        skill_dir = script_dir.parent.resolve()  # skillæ ¹ç›®å½•
        
        # æ£€æµ‹å½“å‰å·¥ä½œç›®å½•æ˜¯å¦æ˜¯skillç›®å½•ï¼ˆé€šè¿‡æ£€æŸ¥æ˜¯å¦å­˜åœ¨SKILL.mdï¼‰
        # å¤§æ¨¡å‹æ‰§è¡Œæ—¶ä¼šcdåˆ°skillç›®å½•ï¼Œæ‰€ä»¥éœ€è¦æ£€æµ‹
        is_skill_dir = (current_cwd / "SKILL.md").exists() or \
                      (current_cwd == skill_dir) or \
                      (current_cwd == script_dir)
        
        if is_skill_dir:
            # å¦‚æœæ˜¯åœ¨skillç›®å½•æ‰§è¡Œï¼Œä½¿ç”¨ç”¨æˆ·ä¸»ç›®å½•ä¸‹çš„å›ºå®šä½ç½®
            home_dir = Path.home()
            # ä½¿ç”¨ Downloads/douyin-video-text ä½œä¸ºé»˜è®¤ä¸‹è½½ä½ç½®
            args.output_dir = str(home_dir / "Downloads" / "douyin-video-text")
            print(f"ğŸ’¡ æ£€æµ‹åˆ°åœ¨skillç›®å½•æ‰§è¡Œï¼Œæ–‡ä»¶å°†ä¿å­˜åˆ°: {args.output_dir}")
        else:
            # å¦‚æœä¸åœ¨skillç›®å½•ï¼Œä½¿ç”¨å½“å‰å·¥ä½œç›®å½•ï¼ˆç”¨æˆ·æ­£å¸¸è°ƒç”¨ï¼‰
            args.output_dir = str(current_cwd / 'downloads')
    
    session = create_session()
    
    try:
        print(f"æ­£åœ¨è§£ææŠ–éŸ³åˆ†äº«é“¾æ¥: {args.url}")
        result = parse_share_url(args.url, session)
        
        print('è§£ææˆåŠŸï¼')
        print('')
        print('è§†é¢‘ä¿¡æ¯:')
        print(f'æ ‡é¢˜: {result.get("title", "æœªè·å–åˆ°")}')
        print(f'è§†é¢‘é“¾æ¥: {result.get("video_url", "æ— ï¼ˆå›¾é›†ï¼‰")}')
        print(f'å°é¢: {result.get("cover_url", "æœªè·å–åˆ°")}')
        
        if result.get('images'):
            print('')
            print(f'å›¾é›†å›¾ç‰‡ ({len(result["images"])} å¼ ):')
            for index, image in enumerate(result['images']):
                print(f'  å›¾ç‰‡ {index + 1}: {image["url"]}')
                if image.get('live_photo_url'):
                    print(f'    Live Photo: {image["live_photo_url"]}')
        
        if result.get('author'):
            print('')
            print('ä½œè€…ä¿¡æ¯:')
            print(f'æ˜µç§°: {result["author"].get("name", "")}')
            print(f'UID: {result["author"].get("uid", "")}')
            print(f'å¤´åƒ: {result["author"].get("avatar", "")}')
        
        # ä¸‹è½½è§†é¢‘
        video_url = result.get('video_url')
        if video_url:
            output_dir = Path(args.output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨è§†é¢‘IDæˆ–æ ‡é¢˜ï¼‰
            video_id = parse_video_id_from_path(args.url)
            if not video_id:
                video_id = 'video'
            filename = f"{video_id}.mp4"
            output_path = output_dir / filename
            
            print('')
            print(f'æ­£åœ¨ä¸‹è½½è§†é¢‘åˆ°: {output_path}')
            download_video(video_url, output_path, session)
            print(f'è§†é¢‘ä¸‹è½½å®Œæˆ: {output_path}')
            
            # è½¬æ–‡å­—
            if args.transcribe:
                print('')
                print('æ­£åœ¨è½¬æ–‡å­—...')
                # å¯¼å…¥transcribeå‡½æ•°ï¼ˆä»åŒç›®å½•çš„transcribe_audio_funasr.pyï¼‰
                script_dir = Path(__file__).parent
                transcribe_script = script_dir / 'transcribe_audio_funasr.py'
                
                if transcribe_script.exists():
                    import importlib.util
                    spec = importlib.util.spec_from_file_location("transcribe_audio_funasr", transcribe_script)
                    transcribe_module = importlib.util.module_from_spec(spec)
                    spec.loader.exec_module(transcribe_module)
                    
                    transcribe_result = transcribe_module.transcribe_audio(
                        str(output_path),
                        model=args.model,
                        vad_model=args.vad_model,
                        punc_model=args.punc_model
                    )
                    
                    if transcribe_result.get('code') == 'SUCCESS':
                        text = transcribe_result['data']['text']
                        print('')
                        print('è½¬æ–‡å­—æˆåŠŸï¼')
                        print('è¯†åˆ«æ–‡æœ¬:')
                        print(text)
                        
                        # ä¿å­˜æ–‡æœ¬åˆ°æ–‡ä»¶
                        text_file = output_path.with_suffix('.txt')
                        text_file.write_text(text, encoding='utf-8')
                        print(f'æ–‡æœ¬å·²ä¿å­˜åˆ°: {text_file}')
                    else:
                        print(f'è½¬æ–‡å­—å¤±è´¥: {transcribe_result.get("message", "æœªçŸ¥é”™è¯¯")}')
                else:
                    print(f'è­¦å‘Š: æ‰¾ä¸åˆ° transcribe_audio_funasr.py æ–‡ä»¶: {transcribe_script}')
        else:
            print('')
            print('æ³¨æ„: è¿™æ˜¯å›¾é›†ï¼Œæ²¡æœ‰è§†é¢‘å¯ä¸‹è½½')
        
        # è¾“å‡ºJSONæ ¼å¼ç»“æœ
        print('')
        print('JSONæ ¼å¼:')
        print(json.dumps(result, ensure_ascii=False, indent=2))
        
        return 0
        
    except Exception as e:
        print(f'è§£æå¤±è´¥: {str(e)}', file=sys.stderr)
        return 1


if __name__ == "__main__":
    sys.exit(main())
